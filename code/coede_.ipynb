{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5YsYS8bLNiC"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import pandas as pd\n",
        "import random\n",
        "import csv\n",
        "from sklearn.metrics import f1_score\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "# Replace with your Hugging Face access token and model ID\n",
        "access_token = \"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\"\n",
        "model_id = \"meta-llama/Meta-Llama-3.2-11B-Instruct\"\n",
        "\n",
        "# Load the tokenizer and model\n",
        "print(\"Loading LLaMA 3.2 11B model...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=access_token)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, use_auth_token=access_token, device_map=\"auto\")\n",
        "llama_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_length=800, device=0)\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "def ask_question_llama(prompt, question, max_length=800, temperature=0.7):\n",
        "    try:\n",
        "        full_prompt = f\"{prompt}\\n{question}\"\n",
        "        response = llama_pipeline(full_prompt, max_length=max_length, temperature=temperature, return_full_text=False)\n",
        "        llama_answer = response[0]['generated_text'].strip().lower()\n",
        "        processed_answer = llama_answer.translate(str.maketrans('', '', string.punctuation)).strip().lower()\n",
        "        return llama_answer, processed_answer\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def summarize_relation(predicted_value):\n",
        "    question = f\"Summarize the term '{predicted_value}' to one of the following: 'activation', 'inhibition', or 'no information'.\"\n",
        "    llama_answer, final_answer = ask_question_llama(\"\", question)\n",
        "    return final_answer\n",
        "\n",
        "def calculate_metrics(df):\n",
        "    relations = ['activation', 'inhibition']\n",
        "    f1_scores = []\n",
        "\n",
        "    df['processed_predict_relation'] = df['predict_relation'].apply(\n",
        "        lambda x: x if x in relations or x == \"no information\" else summarize_relation(x))\n",
        "\n",
        "    for relation in relations:\n",
        "        true_values = (df['relation'] == relation)\n",
        "        predicted_values = (df['processed_predict_relation'] == relation)\n",
        "        try:\n",
        "            f1 = f1_score(true_values, predicted_values)\n",
        "        except ValueError:\n",
        "            f1 = 0\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    overall_f1 = f1_score(df['relation'], df['processed_predict_relation'], average='micro')\n",
        "    return overall_f1, f1_scores\n",
        "\n",
        "def get_fitness(prompt, instruction, training_file=\"training.csv\"):\n",
        "    \"\"\"\n",
        "    Evaluate the fitness of a prompt using the LLaMA model and data from training.csv.\n",
        "    \"\"\"\n",
        "    training_df = pd.read_csv(training_file)\n",
        "\n",
        "    dp = \"Example: Q: What effect does gene EGF have on gene EGFR? A: Activation. \" \\\n",
        "         \"Q: What effect does gene GRK2 have on gene OR2AJ1? A: Inhibition. \" \\\n",
        "         \"Q: What effect does gene CDK9 have on gene NELFB? A: No information.\"\n",
        "\n",
        "    training_df = training_df.sample(frac=1).reset_index(drop=True)\n",
        "    answers = []\n",
        "\n",
        "    for _, row in training_df.iterrows():\n",
        "        starter = row['starter']\n",
        "        receiver = row['receiver']\n",
        "        relation = row['relation_name']\n",
        "\n",
        "        llama_answer, relation1 = ask_question_llama(prompt + '\\n' + dp, instruction.format(gene1=starter.upper(), gene2=receiver.upper()))\n",
        "        answers.append({'starter': starter, 'receiver': receiver, 'relation': relation,\n",
        "                        'LLaMA_answer': llama_answer, 'predict_relation': relation1, 'prompt': instruction})\n",
        "\n",
        "    answer_df = pd.DataFrame(answers)\n",
        "    overall_f1, f1_scores = calculate_metrics(answer_df)\n",
        "    return overall_f1\n",
        "\n",
        "def evaluate_prompts(roles, aims, instructions, descriptions, training_file=\"training.csv\"):\n",
        "    fitness_scores = []\n",
        "    for role, aim, instruction, description in zip(roles, aims, instructions, descriptions):\n",
        "        prompt = f\"Act as a {role}, {aim}, {instruction}, {description}\"\n",
        "        fitness_value = get_fitness(prompt, instruction, training_file=training_file)\n",
        "        fitness_scores.append(fitness_value)\n",
        "    return fitness_scores\n",
        "\n",
        "def normalize_scores(f1_scores):\n",
        "    min_val, max_val = min(f1_scores), max(f1_scores)\n",
        "    return [(score - min_val) / (max_val - min_val) if max_val - min_val != 0 else 1 for score in f1_scores]\n",
        "\n",
        "def initialize_population(roles, aims, instructions, descriptions, training_file=\"training.csv\"):\n",
        "    population = list(zip(roles, aims, instructions, descriptions))\n",
        "    fitness = evaluate_prompts(roles, aims, instructions, descriptions, training_file=training_file)\n",
        "    normalized_fitness = normalize_scores(fitness)\n",
        "\n",
        "    pwf = [(individual, score) for individual, score in zip(population, normalized_fitness)]\n",
        "    return pwf\n",
        "\n",
        "def tournament_selection(pwf, tournament_size=5):\n",
        "    tournament = random.sample(pwf, tournament_size)\n",
        "    return max(tournament, key=lambda x: x[1])[0]\n",
        "\n",
        "def single_point_crossover(parent1, parent2):\n",
        "    crossover_point = random.randint(1, len(parent1) - 1)\n",
        "    offspring1 = parent1[:crossover_point] + parent2[crossover_point:]\n",
        "    offspring2 = parent2[:crossover_point] + parent1[crossover_point:]\n",
        "    return offspring1, offspring2\n",
        "\n",
        "def perform_crossover(pwf, crossover_rate=0.7, tournament_size=5):\n",
        "    new_population = []\n",
        "    while len(new_population) < len(pwf):\n",
        "        parent1 = tournament_selection(pwf, tournament_size)\n",
        "        parent2 = tournament_selection(pwf, tournament_size)\n",
        "        if random.random() < crossover_rate:\n",
        "            offspring1, offspring2 = single_point_crossover(parent1, parent2)\n",
        "            new_population.append(offspring1)\n",
        "            new_population.append(offspring2)\n",
        "        else:\n",
        "            new_population.append(parent1)\n",
        "            new_population.append(parent2)\n",
        "    return new_population[:len(pwf)]\n",
        "\n",
        "def mutate_individual(individual, mutation_rate=0.3, population=None):\n",
        "    if population is None:\n",
        "        return individual\n",
        "\n",
        "    roles, aims, instructions, descriptions = zip(*population)\n",
        "    mutated_individual = list(individual)\n",
        "\n",
        "    for i in range(len(mutated_individual)):\n",
        "        if random.random() < mutation_rate:\n",
        "            if i == 0:  # Mutate \"role\"\n",
        "                mutated_individual[i] = random.choice(roles)\n",
        "            elif i == 1:  # Mutate \"aim\"\n",
        "                mutated_individual[i] = random.choice(aims)\n",
        "            elif i == 2:  # Mutate \"instruction\"\n",
        "                mutated_individual[i] = random.choice(instructions)\n",
        "            elif i == 3:  # Mutate \"description\"\n",
        "                mutated_individual[i] = random.choice(descriptions)\n",
        "\n",
        "    return tuple(mutated_individual)\n",
        "\n",
        "def perform_mutation(population, mutation_rate=0.3):\n",
        "    return [mutate_individual(individual, mutation_rate, population) for individual in population]\n",
        "\n",
        "def write_to_csv(population, fitness_scores, filename=\"adjusted.csv\"):\n",
        "    with open(filename, \"w\", newline='') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "        csv_writer.writerow([\"role\", \"aim\", \"instruction\", \"description\", \"normalized_fitness\"])\n",
        "        for individual, fitness in zip(population, fitness_scores):\n",
        "            role, aim, instruction, description = individual\n",
        "            csv_writer.writerow([role, aim, instruction, description, fitness])\n",
        "\n",
        "# Usage\n",
        "df = pd.read_csv(\"merged_initial_v828.csv\")\n",
        "roles, aims, instructions, descriptions = df['roles'].tolist(), df['aims'].tolist(), df['instructions'].tolist(), df['descriptions'].tolist()\n",
        "pop_with_fitness = initialize_population(roles, aims, instructions, descriptions, training_file=\"training.csv\")\n",
        "new_generation = perform_crossover(pop_with_fitness, crossover_rate=0.7)\n",
        "mutated_generation = perform_mutation(new_generation, mutation_rate=0.3)\n",
        "new_fitness = evaluate_prompts(*zip(*mutated_generation), training_file=\"val.csv\")\n",
        "normalized_new_fitness = normalize_scores(new_fitness)\n",
        "write_to_csv(mutated_generation, normalized_new_fitness)\n"
      ]
    }
  ]
}