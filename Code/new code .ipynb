{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5YsYS8bLNiC"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import pandas as pd\n",
        "import openai\n",
        "import random\n",
        "import csv\n",
        "import time\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "\n",
        "def ask_question(prompt, question, temperature):\n",
        "    max_retries = 5\n",
        "    backoff_factor = 2\n",
        "\n",
        "    for retries in range(max_retries):\n",
        "        try:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": prompt},\n",
        "                    {\"role\": \"user\", \"content\": question},\n",
        "                ],\n",
        "                max_tokens=800,\n",
        "                temperature=temperature,\n",
        "            )\n",
        "\n",
        "            for choice in response['choices']:\n",
        "                gpt_answer = choice['message']['content'].strip().lower()\n",
        "                final_answer = gpt_answer.translate(str.maketrans('', '', string.punctuation)).strip().lower()\n",
        "                return gpt_answer, final_answer\n",
        "\n",
        "        except openai.APIError as e:\n",
        "            if retries == max_retries - 1:\n",
        "                print(f\"An error occurred while making the API request: {e}\")\n",
        "                return None, None, None\n",
        "            else:\n",
        "                sleep_time = backoff_factor * (2 ** retries)\n",
        "                print(f\"An API error occurred while making the API request: {e}. Retrying in {sleep_time} seconds...\")\n",
        "                time.sleep(sleep_time)\n",
        "\n",
        "        except openai.error.RateLimitError as e:\n",
        "            if retries == max_retries - 1:  # If this is the last retry attempt, return None values\n",
        "                print(f\"An error occurred while making the API request: {e}\")\n",
        "                return None, None, None\n",
        "            else:\n",
        "                # Calculate the sleep time using exponential backoff and sleep\n",
        "                sleep_time = backoff_factor * (2 ** retries)\n",
        "                print(f\"An rate limit error occurred while making the API request: {e}. Retrying in {60} seconds...\")\n",
        "                time.sleep(sleep_time)\n",
        "\n",
        "        except openai.error.Timeout as e:\n",
        "            if retries == max_retries - 1:  # If this is the last retry attempt, return None values\n",
        "                print(f\"An error occurred while making the API request: {e}\")\n",
        "                return None, None\n",
        "            else:\n",
        "                # Calculate the sleep time using exponential backoff and sleep\n",
        "                sleep_time = backoff_factor * (2 ** retries)\n",
        "                print(f\"An timeout error occurred while making the API request: {e}. Retrying in {sleep_time} seconds...\")\n",
        "                time.sleep(sleep_time)\n",
        "\n",
        "        except openai.error.ServiceUnavailableError as e:\n",
        "            if retries == max_retries - 1:  # If this is the last retry attempt, return None values\n",
        "                print(f\"An error occurred while making the API request: {e}\")\n",
        "                return None, None, None\n",
        "            else:\n",
        "                # Calculate the sleep time using exponential backoff and sleep\n",
        "                sleep_time = backoff_factor * (2 ** retries)\n",
        "                print(f\"Service Unavailable error: {e}. The server is overloaded or not ready yet. Retrying in {sleep_time} seconds...\")\n",
        "                time.sleep(sleep_time)\n",
        "\n",
        "\n",
        "def summarize_relation(predicted_value):\n",
        "    \"\"\"\n",
        "    Ask GPT-3.5-turbo to summarize the predicted_value into one of:\n",
        "    'activation', 'inhibition', 'phosphorylation', or 'no information'.\n",
        "\n",
        "    Parameters:\n",
        "        predicted_value (str): The value to be summarized.\n",
        "\n",
        "    Returns:\n",
        "        str: The summarized relation or None if an error occurs.\n",
        "    \"\"\"\n",
        "    # Prompt structure\n",
        "    question = f\"Summarize the term '{predicted_value}' to one of the following: 'activation', 'inhibition', \" \\\n",
        "               f\"'phosphorylation', or 'no information'. \"\n",
        "\n",
        "    # Call GPT-3.5-turbo\n",
        "    gpt_answer, final_answer = ask_question(\"\", question, 0)\n",
        "\n",
        "    # Post-process the answer: remove punctuation and convert to lowercase\n",
        "    if final_answer:\n",
        "        final_answer = final_answer.translate(str.maketrans('', '', string.punctuation)).strip().lower()\n",
        "\n",
        "    return final_answer\n",
        "\n",
        "\n",
        "def calculate_metrics(df):\n",
        "    # Define the unique relations\n",
        "    relations = ['activation', 'inhibition', 'phosphorylation']\n",
        "\n",
        "    f1_scores = []\n",
        "\n",
        "    # Process and potentially correct the predicted values\n",
        "    df['processed_predict_relation'] = df['predict_relation'].apply(\n",
        "        lambda x: x if x in relations or x == \"no information\" else summarize_relation(x))\n",
        "\n",
        "    print(\"Unique values in df['relation']:\", df['relation'].unique())\n",
        "    print(\"Unique values in df['processed_predict_relation']:\", df['processed_predict_relation'].unique())\n",
        "    print(\"Unique values in df['predict_relation']:\", df['predict_relation'].unique())\n",
        "\n",
        "    # Calculate metrics for each relation\n",
        "    for relation in relations:\n",
        "        true_values = (df['relation'] == relation)\n",
        "        predicted_values = (df['processed_predict_relation'] == relation)\n",
        "\n",
        "        try:\n",
        "            f1 = f1_score(true_values, predicted_values)\n",
        "        except ValueError:\n",
        "            f1 = 0\n",
        "\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    overall_f1 = f1_score(df['relation'], df['processed_predict_relation'], average='micro')\n",
        "\n",
        "    return overall_f1, f1_scores\n",
        "\n",
        "\n",
        "def get_fitness(prompt, question, temperature=0.3):\n",
        "    training_path = \"val.csv\"\n",
        "    training_df = pd.read_csv(training_path)\n",
        "\n",
        "    dp = \"Example: Q: What effect does gene EGF have on gene EGFR? A: Activation. Q: What effect does gene GRK2 have \" \\\n",
        "         \"on gene OR2AJ1? A: Inhibition. Q: What effect does gene CDK9 have on gene NELFB? A: Phosphorylation. Make \" \\\n",
        "         \"sure your answer is definitive, composed of 'activation', 'inhibition', 'phosphorylation' or 'no \" \\\n",
        "         \"information' without further details or explanation. \"\n",
        "\n",
        "    # shuffle the dataset\n",
        "    training_df = training_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    answers = []\n",
        "\n",
        "    for index, row in training_df.iterrows():\n",
        "        starter = row['starter']\n",
        "        receiver = row['receiver']\n",
        "        relation = row['relation_name']\n",
        "\n",
        "        gpt_answer, relation1 = ask_question(prompt + '\\n' + dp,\n",
        "                                             question.format(gene1=starter.upper(), gene2=receiver.upper()),\n",
        "                                             temperature)\n",
        "        print(\"gpt_answer: \", gpt_answer)\n",
        "        print(\"relation1: \", relation1)\n",
        "        answers.append({'starter': starter, 'receiver': receiver, 'relation': relation,\n",
        "                        'GPT_answer': gpt_answer, 'predict_relation': relation1, 'prompt': question})\n",
        "\n",
        "    answer_df = pd.DataFrame(answers)\n",
        "\n",
        "    overall_f1, f1_scores = calculate_metrics(answer_df)\n",
        "\n",
        "    return overall_f1\n",
        "\n",
        "\n",
        "def read_csv_file(file_name):\n",
        "    \"\"\"\n",
        "    Read a CSV file and return its columns as lists.\n",
        "\n",
        "    Parameters:\n",
        "        file_name (str): Path to the CSV file.\n",
        "\n",
        "    Returns:\n",
        "        list, list, list, list: Lists containing the values of the columns 'roles', 'tasks', 'general_instructions', and 'user_questions' respectively.\n",
        "    \"\"\"\n",
        "\n",
        "    # Read the CSV file into a DataFrame\n",
        "    df = pd.read_csv(file_name)\n",
        "\n",
        "    # Extract each column into a list\n",
        "    r = df['roles'].tolist()\n",
        "    t = df['tasks'].tolist()\n",
        "    g = df['general_instructions'].tolist()\n",
        "    u = df['user_questions'].tolist()\n",
        "\n",
        "    return r, t, g, u\n",
        "\n",
        "\n",
        "def assemble_prompt(role, task, general_instruction):\n",
        "    \"\"\"\n",
        "    Assemble a prompt using the given role, task, and general instruction.\n",
        "\n",
        "    Parameters:\n",
        "        role (str): Role for the prompt.\n",
        "        task (str): Task for the prompt.\n",
        "        general_instruction (str): General instruction for the prompt.\n",
        "\n",
        "    Returns:\n",
        "        str: Assembled prompt.\n",
        "    \"\"\"\n",
        "    return f\"Act as a {role}, {task}, {general_instruction}\"\n",
        "\n",
        "\n",
        "def evaluate_prompts(r, t, gis, uqs):\n",
        "    \"\"\"\n",
        "    Evaluate prompts using the get_fitness function.\n",
        "\n",
        "    Parameters:\n",
        "        r (list): List of roles.\n",
        "        t (list): List of tasks.\n",
        "        gis (list): List of general instructions.\n",
        "        uqs (list): List of user questions.\n",
        "\n",
        "    Returns:\n",
        "        list: List of fitness values for each prompt.\n",
        "    \"\"\"\n",
        "    f = []\n",
        "\n",
        "    for role, task, general_instruction, question in zip(r, t, gis, uqs):\n",
        "        prompt = assemble_prompt(role, task, general_instruction)\n",
        "        fitness_value = get_fitness(prompt, question)\n",
        "        f.append(fitness_value)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def normalize_scores(f1_scores):\n",
        "    \"\"\"\n",
        "    Normalize a list of F-1 scores to [0,1] range using Min-Max scaling.\n",
        "\n",
        "    Parameters:\n",
        "        f1_scores (list): List of original F-1 scores.\n",
        "\n",
        "    Returns:\n",
        "        list: List of normalized F-1 scores.\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate the minimum and maximum values in the list\n",
        "    min_val = min(f1_scores)\n",
        "    max_val = max(f1_scores)\n",
        "\n",
        "    # Check if the range (max-min) is zero to avoid division by zero\n",
        "    if max_val - min_val == 0:\n",
        "        return [1 for score in f1_scores]  # if all values are the same, return a list of 1s\n",
        "\n",
        "    # Normalize scores using min-max scaling\n",
        "    normalized_scores = [(score - min_val) / (max_val - min_val) for score in f1_scores]\n",
        "\n",
        "    return normalized_scores\n",
        "\n",
        "\n",
        "def initialize_population(r, t, gis, uqs):\n",
        "    \"\"\"\n",
        "    Initialize the population by combining roles, tasks, general_instructions,\n",
        "    and user_questions into a list of tuples. Then, evaluate fitness for each individual.\n",
        "\n",
        "    Parameters:\n",
        "        r (list): List of roles.\n",
        "        t (list): List of tasks.\n",
        "        gis (list): List of general instructions.\n",
        "        uqs (list): List of user questions.\n",
        "\n",
        "    Returns:\n",
        "        list: Population with associated fitness.\n",
        "    \"\"\"\n",
        "    # Combine roles, tasks, general_instructions, and user_questions into tuples\n",
        "    population = list(zip(r, t, gis, uqs))\n",
        "\n",
        "    # Evaluate fitness for each individual in the population\n",
        "    fitness = evaluate_prompts(r, t, gis, uqs)\n",
        "\n",
        "    # Normalize the scores\n",
        "    normalized_fitness = normalize_scores(fitness)\n",
        "\n",
        "    # Combine the population with their normalized fitness scores\n",
        "    pwf = [(individual, score) for individual, score in zip(population, normalized_fitness)]\n",
        "\n",
        "    # Create a DataFrame from the data\n",
        "    df = pd.DataFrame({\n",
        "        'role': r,\n",
        "        'tasks': t,\n",
        "        'general_instructions': gis,\n",
        "        'user_questions': uqs,\n",
        "        'fitness_score': normalized_fitness\n",
        "    })\n",
        "\n",
        "    # Write the DataFrame to a CSV file\n",
        "    df.to_csv('initial_population.csv', index=False)\n",
        "\n",
        "    return pwf\n",
        "\n",
        "\n",
        "def tournament_selection(pwf, tournament_size):\n",
        "    \"\"\"\n",
        "    Perform tournament selection on the population.\n",
        "\n",
        "    Parameters:\n",
        "        pwf (list): A list of tuples containing individual and its fitness.\n",
        "        tournament_size (int): Number of individuals in each tournament.\n",
        "\n",
        "    Returns:\n",
        "        individual: A selected parent individual from the population.\n",
        "    \"\"\"\n",
        "    # Randomly select 'tournament_size' individuals from the population\n",
        "    tournament = random.sample(pwf, tournament_size)\n",
        "\n",
        "    # Select the one with the highest fitness\n",
        "    winner = max(tournament, key=lambda x: x[1])[0]\n",
        "\n",
        "    return winner\n",
        "\n",
        "\n",
        "def single_point_crossover(parent1, parent2):\n",
        "    \"\"\"\n",
        "    Perform single-point crossover on two parents.\n",
        "\n",
        "    Parameters:\n",
        "        parent1, parent2 (tuple): Two parent individuals.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Two offspring produced from the parents.\n",
        "    \"\"\"\n",
        "    # Choose a crossover point\n",
        "    crossover_point = random.randint(1, len(parent1) - 1)\n",
        "\n",
        "    # Create offspring\n",
        "    offspring1 = parent1[:crossover_point] + parent2[crossover_point:]\n",
        "    offspring2 = parent2[:crossover_point] + parent1[crossover_point:]\n",
        "\n",
        "    return offspring1, offspring2\n",
        "\n",
        "\n",
        "def perform_crossover(pwf, crossover_rate=0.8, tournament_size=5):\n",
        "    \"\"\"\n",
        "    Perform crossover operation over the entire population.\n",
        "\n",
        "    Parameters:\n",
        "        pwf (list): A list of tuples containing individual and its fitness.\n",
        "        crossover_rate (float): The probability of two individuals crossing over to produce offspring.\n",
        "        tournament_size (int): Number of individuals in each tournament.\n",
        "\n",
        "    Returns:\n",
        "        list: A new generation of the population.\n",
        "    \"\"\"\n",
        "    new_population = []\n",
        "\n",
        "    while len(new_population) < len(pwf):\n",
        "        # Select two parents using tournament selection\n",
        "        parent1 = tournament_selection(pwf, tournament_size)\n",
        "        parent2 = tournament_selection(pwf, tournament_size)\n",
        "\n",
        "        # Perform crossover based on the given rate\n",
        "        if random.random() < crossover_rate:\n",
        "            offspring1, offspring2 = single_point_crossover(parent1, parent2)\n",
        "            new_population.append(offspring1)\n",
        "            new_population.append(offspring2)\n",
        "        else:\n",
        "            new_population.append(parent1)\n",
        "            new_population.append(parent2)\n",
        "\n",
        "    return new_population[:len(pwf)]  # Ensure the new population size is the same as the old one\n",
        "\n",
        "\n",
        "def write_to_csv(population, fitness_scores, filename=\"adjusted.csv\"):\n",
        "    \"\"\"\n",
        "    Write the population and their fitness to a CSV file.\n",
        "\n",
        "    Parameters:\n",
        "        population (list): A list of individuals.\n",
        "        fitness_scores (list): List of fitness scores corresponding to each individual.\n",
        "        filename (str): The name of the CSV file to write to.\n",
        "    \"\"\"\n",
        "    with open(filename, \"w\", newline='') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "\n",
        "        # Write the header\n",
        "        csv_writer.writerow([\"role\", \"task\", \"general_instructions\", \"user_question\", \"normalized_fitness\"])\n",
        "\n",
        "        # Write the population and their fitness\n",
        "        for individual, fitness in zip(population, fitness_scores):\n",
        "            role, task, instruction, question = individual\n",
        "            csv_writer.writerow([role, task, instruction, question, fitness])\n",
        "\n",
        "\n",
        "# Usage\n",
        "roles, tasks, general_instructions, user_questions = read_csv_file(\"merged_initial_v828.csv\")\n",
        "pop_with_fitness = initialize_population(roles, tasks, general_instructions, user_questions)\n",
        "new_generation = perform_crossover(pop_with_fitness)\n",
        "# Evaluate the new generation's fitness\n",
        "new_fitness = evaluate_prompts(*zip(*new_generation))  # Unzipping the population to get separate lists\n",
        "\n",
        "# Normalize the computed fitness scores\n",
        "normalized_new_fitness = normalize_scores(new_fitness)\n",
        "\n",
        "# Write the new population and their normalized fitness to a CSV file\n",
        "write_to_csv(new_generation, normalized_new_fitness)"
      ]
    }
  ]
}